# Dataset Utilized: Android Adware and General Malware Dataset (CIC-AAGM2017)
# File: https://www.unb.ca/cic/datasets/pdfmal-2022.html
# Citation: Arash Habibi Lashkari, Andi Fitriah A. Kadir, Hugo Gonzalez, Kenneth Fon Mbah and Ali A. Ghorbani,
# “Towards a Network-Based Framework for Android Malware Detection and Characterization”, In the proceeding of
# the 15th International Conference on Privacy, Security and Trust, PST, Calgary, Canada, 2017.

# CIC-AAGM2017 2-Class Malware Detection
# Cleaning (num_outbound_cmds, su_attempted), Class Assignment (binary), Label Encoding, Feature Selection (MAD), Random Forest

# Written in Anaconda Spyder 5.5.0 IDE using Python 3.9.18 64-bit on Windows 10

# Necessary Imports
import numpy as np
import pandas as pd
import pickle
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, matthews_corrcoef
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split

#%%

"""Load Dataset"""

dataset = pd.read_csv('TotalFeatures-ISCXFlowMeter.csv') # Make sure the file has dropped in the directory first and the name matches

# Merge attack labels 'adware' and 'GeneralMalware' to simply 'malware' class for binary classification
dataset['class'].replace(['adware', 'GeneralMalware'],'malware',inplace=True) # 2 subclasses

#%%

"""Clean Data"""

# We drop 'furg_cnt', 'burg_cnt', 'flow_urg', 'flow_cwr', 'flow_ece' because every instance is equal to 0 in the dataset

columns_to_drop = ['furg_cnt', 'burg_cnt', 'flow_urg', 'flow_cwr', 'flow_ece']

for column in columns_to_drop:
    if column in dataset.columns:
        dataset.drop(column, axis=1, inplace=True)


#%%

"""Preprocess Data"""

# Preprocess just the class label

# Encode class label with LabelEncoder
label_encoder = preprocessing.LabelEncoder()
dataset['class'] = label_encoder.fit_transform(dataset['class'])

# Preprocess the rest of the data

# Define the columns to LabelEncode (there is no categorical data to encode for this dataset)
categorical_columns=[] # Empty

# Encode categorical columns using LabelEncoder
label_encoder = preprocessing.LabelEncoder()
for column in categorical_columns:
    dataset[column] = label_encoder.fit_transform(dataset[column])

# Define the columns to scale (74 Unique Numerical Features)
columns_to_scale=['duration', 'total_fpackets', 'total_bpackets', 'total_fpktl', 'total_bpktl', 'min_fpktl', 'min_bpktl', 'max_fpktl', 'max_bpktl', 'mean_fpktl', 'mean_bpktl', 'std_fpktl',
                  'std_bpktl', 'total_fiat', 'total_biat', 'min_fiat', 'min_biat', 'max_fiat', 'max_biat', 'mean_fiat', 'mean_biat', 'std_fiat', 'std_biat', 'fpsh_cnt', 'bpsh_cnt',
                  'total_fhlen', 'total_bhlen', 'fPktsPerSecond', 'bPktsPerSecond', 'flowPktsPerSecond', 'flowBytesPerSecond', 'min_flowpktl', 'max_flowpktl', 'mean_flowpktl', 'std_flowpktl',
                  'min_flowiat', 'max_flowiat', 'mean_flowiat', 'std_flowiat', 'flow_fin', 'flow_syn', 'flow_rst', 'flow_psh', 'flow_ack', 'downUpRatio', 'avgPacketSize', 'fAvgSegmentSize',
                  'fHeaderBytes', 'fAvgBytesPerBulk', 'fAvgPacketsPerBulk', 'fAvgBulkRate', 'bVarianceDataBytes', 'bAvgSegmentSize', 'bAvgBytesPerBulk', 'bAvgPacketsPerBulk', 'bAvgBulkRate',
                  'sflow_fpacket', 'sflow_fbytes', 'sflow_bpacket', 'sflow_bbytes', 'min_active', 'mean_active', 'max_active', 'std_active', 'min_idle', 'mean_idle', 'max_idle', 'std_idle', 'FFNEPD',
                  'Init_Win_bytes_forward', 'Init_Win_bytes_backward', 'RRT_samples_clnt', 'Act_data_pkt_forward', 'min_seg_size_forward']

# Scale numerical columns using MinMax
scaler = MinMaxScaler()
for column in columns_to_scale:
    dataset[column] = scaler.fit_transform(dataset[[column]])

# Assign all features except the last feature ('class') to X and make the Target Variable Y equal to 'class'
X = dataset.iloc[:, :-1].values
y = dataset['class'].values

#%%

"""Split the Dataset for Training and Testing"""

# Split the large dataset into by 70% Training and 30% Testing (can be adjusted by changing the value for test_size)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Feature count should now be equal (74 features) along with a 70/30 split of total samples
print("X Training Shape:", X_train.shape)
print("X Testing Shape:", X_test.shape)

#%%

"""Run ML Algorithm and Test Performance"""

# Data cleaning and preprocessing has been applied prior to training
# **More steps such as feature selection, editing fine tuning hyperparameters, autoencoders, etc. can be applied later**
# Random Forest ML Algorithm

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, matthews_corrcoef
from sklearn.model_selection import cross_val_score

# Create a RandomForestClassifier
clf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)

# Perform k-fold cross-validation (k = 10)
cv_scores = cross_val_score(clf, X_train, y_train, cv=2, n_jobs=-1)

# Train the model on the entire training set
clf.fit(X_train, y_train)

# Evaluate the model on the test set
y_pred = clf.predict(X_test)

# Print the cross-validation scores
print("Cross-Validation Scores:")
print(cv_scores)
print("\nMean CV Score:", cv_scores.mean(),"\n")

# Print classification report and confusion matrix on the test set
print("Classification Report:")
print(classification_report(y_test, y_pred, digits=4))

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred), "\n")

# Calculate AUC
y_prob = clf.predict_proba(X_test)[:, 1]  # Get the probability of the malware class
auc_score = roc_auc_score(y_test, y_prob)
print("AUC Score:", auc_score)

# Calculate MCC
mcc_score = matthews_corrcoef(y_test, y_pred)
print("MCC Score:", mcc_score)

#%%

""" Saving the Model for future use in Scoring Scripts and/or Mobile App """

# Serialize the trained model using pickle
with open('malwareDetection.pkl', 'wb') as f:
    pickle.dump(clf, f)

#%%

# Visualize Results (Heatmap Confusion Matrix)

def plot_confusion_matrix_heatmap_with_values(cm, classes, title, cmap=plt.cm.Blues):
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    tick_marks = np.arange(len(classes))
    sorted_classes = sorted(list(classes))  # Convert set to list and sort it
    plt.xticks(tick_marks, sorted_classes, rotation=45)
    plt.yticks(tick_marks, sorted_classes)

    fmt = '.2f' if cm.max() < 1 else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, format(cm[i, j], fmt),
                     ha="center", va="center",
                     color="white" if cm[i, j] > thresh else "black")

    plt.xlabel('Predicted Class')
    plt.ylabel('True Class')

class_numbers = {0,1}
class_names = {'benign', 'malware'}

# Original Confusion Matrix
cm_original = confusion_matrix(y_test, y_pred)
plot_confusion_matrix_heatmap_with_values(cm_original, class_names, 'Malware Detection')

# Call plt.tight_layout() before saving
plt.tight_layout()

plt.savefig('Heatmap_400dpi.png', dpi=400)  # Saving with 400 dpi